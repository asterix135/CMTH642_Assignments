Notes for analysis

From source page:
"These datasets can be viewed as classification or regression tasks. The classes are ordered and not balanced (e.g. there are munch more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods."

Note: several of the attributes may be correlated, thus it makes sense to apply some sort of feature selection.

Original paper used:
- Support Vector Machine
- Multiple Regression
- Neural Networks


## Dealing with an Unbalanced Training Set
https://www.quora.com/In-classification-how-do-you-handle-an-unbalanced-training-set

    Replicate data points for the lagging class and add those to the training data (might increase bias)
    Artificially generate more data points by manually tweaking features. This is sometimes done with with systems involving images, where an existing image can be distorted to create a new image. You run the risk of training the model based on (artificial) samples that aren't representative of the test samples that the model would encounter in the real world.
    Treat the multi-class classifier as a binary classifier for the larger sample. Define the larger class as positive and the smaller class as a negative. This would train your model distinctly on what the larger class looks like, and theoretically classifier the smaller class as "negatives". Your performance will depend on how many features you have for your samples and how tolerant your model can be to overfitting.